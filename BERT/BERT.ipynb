{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09378d28",
   "metadata": {},
   "source": [
    "# Bidirectional Encoder Representations from Transformers (BERT)\n",
    "- Here is the [[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)](https://arxiv.org/abs/1810.04805) fully detailing what a BERT is; This model was developed by Google AI\n",
    "    - \"BERT is  designed  to  pre-train  deep  bidirectional  representations  from unlabeled text by jointly conditioning on both left  and  right  context  in  all  layers.\" - arXiv:1810.04805v2\n",
    "- BERT is an innovative architecture that lead to substantial improvement in the <b> natural language inference, question answering, sentiment analysis, text summarization, Next Sentence Prediction and so many other fields! </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3a462",
   "metadata": {},
   "source": [
    "# BERT Pro's and its succession to LSTM\n",
    "- You can think of BERT as the successor to LSTM; [Check out my video on LSTM!](https://www.youtube.com/watch?v=rmxogwIjOhE)\n",
    "    - Drawbacks of LSTM's\n",
    "            - Slow to Train\n",
    "                - Considers words in sequential order (not parallel)\n",
    "            - Not \"really\" bi-directional since LSTM has different \"gates\" that executes that logic (but some is lost)\n",
    "- Different BERT models of varying sizes from the paper [linked in this github](https://github.com/google-research/bert)\n",
    "\n",
    "### <center> LSTM Architecture </center>\n",
    "![LSTM](LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa28bd4",
   "metadata": {},
   "source": [
    "# BERT Architecture\n",
    "- The BERT architecture is a multi-layer bidrectional transformer encoder; Here is a [video](https://www.youtube.com/watch?v=X0tB-J8_TS4) and [github link](https://github.com/SpencerPao/Natural-Language-Processing/tree/main/Transformers)\n",
    "    - So it is <b> literally </b> taking the transformer encoder and stacking the encoders on top of each other!\n",
    "        - The BERT base architecture has 12 encoder blocks, 12 multi-attention heads, and 110 million parameters\n",
    "        - The BERT large architecture has 24 enoder blocks, 16 multi-attention heads, and 340 million parameters\n",
    "\n",
    "Image locations came from: <b> [Attention Is All You Need](https://arxiv.org/abs/1706.03762) </b>\n",
    "\n",
    "Encoder Block             |  Attention Framework\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"Encoder.png\" width=\"300\" height=\"450\"> |  <img src=\"Attention.png\" width=\"600\" height=\"900\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98762c6",
   "metadata": {},
   "source": [
    "# How are BERT's Trained?\n",
    "\n",
    "There are two steps in this framework.\n",
    "\n",
    "### Pre-training\n",
    "The BERT model is trained on unblabeled data over different pre-training tasks. This is how the BERT architecture understands the language and context.\n",
    "It accomplishes this in two ways:\n",
    "- Masked Languaged Model (MLM)\n",
    "    - This just masks words and attempts to predict what word would fit in the masked term.\n",
    "    - Original Sentence: \"Make sure to like and subscribe!\"\n",
    "    - Masking: \"Make sure to <b>[MASK1]</b> and <b>[MASK2]</b>\"\n",
    "    - The Model then attempts to predict what the <b>[MASK1]</b> and <b>[MASK2]</b> by plugging in terms.\n",
    "- Next Sentence Prediction (NSP)\n",
    "    - Similarly to the MLM process, the NSP process attempts to predict the next sentence. (and if the next sentence is actually what it is said to be)\n",
    "    - Original Sentences: \n",
    "        - <b> Prior Sentence </b>: \"Make sure to like and subscribe!\"\n",
    "        - <b> Post Sentence </b>: \"I just hit the like button with notificatons and subscribe button!\"\n",
    "    - Does the post sentence follow the prior sentence?\n",
    "    \n",
    "In industry, you will typically utilize an already existing BERT model that has an already pretrained corpus with its distinct vocabulary and either use the model out of the box or go straght to the fine-tuning phase with your training data.\n",
    "\n",
    "# Overview for pre-training:\n",
    "- Train BERT using NSP and MLM\n",
    "    - Every word in sentence returns token embedding\n",
    "    - Incorporate the segment and positional embeddings to account for ordering of inputs\n",
    "    - Pass into BERT\n",
    "    - Outputs word vectors for MLM and a binary value for NSP\n",
    "    - Word vectors passed into a Softmax Layer with X neurons, where X = number of possible words in vocab\n",
    "    - Compare with Cross Entropy Loss, thereby providing prediction for word.\n",
    "<img src=\"Token_Embeddings.png\" width=\"600\" height=\"900\">\n",
    "\n",
    "\n",
    "### Fine-Tuning\n",
    "The BERT model is initialized with the pre-trained parameters and then <b> all </b> the parameters are fine-tuned with labeled data. This is where the model utilizes the underlying understanding of language and context to attempt to solve a problem.\n",
    "- Replace the output layer of BERT with a fully connected network layer where the number of neurons is the number of words for prediction (for QA type problems); the number of neurons can vary among what type of problem you are attempting to solve.\n",
    "- This process is relatively fast to train since the only parameters that will be updated are the output layer parameters\n",
    "    - The other parmaters (encoder blocks) won't change as dramatically\n",
    " \n",
    "\n",
    "\n",
    "### BERT Structure for various NLP tasks\n",
    "- Tok - is a token which is a word.\n",
    "- E - Embeddings (pretrained embeddings from the pre-training step) -- These are vectors of same size\n",
    "- C - Class Labels\n",
    "- CLS - Classification Output (dependent variables : this can be a binary output for example)\n",
    "- T - represents the contextual representation of a token\n",
    "\n",
    "Image locations came from: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) and more information on how to approach your specific problem can be addressed there.\n",
    "<img src=\"Fine_Tuned_Tasks.png\" width=\"600\" height=\"900\">\n",
    "\n",
    "# Overview for fine-tuning\n",
    "- Provide supervised dataset and tune the neurons in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec03c4f",
   "metadata": {},
   "source": [
    "# Cool. Now, let's start applying BERT!\n",
    "There are of course sooo many applications for BERT:\n",
    "- Determine if a movieâ€™s reviews are positive or negative\n",
    "- Help chatbots answer questions\n",
    "- Help predicts text when writing an email\n",
    "- Can quickly summarize long legal contracts\n",
    "\n",
    "Let's keep it simple and see how it can be applied with Sentiment Analysis! Now as you are probably aware, I have done a Sentiment Analysis Video [here](https://www.youtube.com/watch?v=CzRrD76pnVY) but with an LSTM. So, let's do the same with BERT!\n",
    "\n",
    "We want to predict if the text has a POSITIVE or NEGATIVE sentiment associated.\n",
    "- We are going to be conducting Sentiment Analysis.\n",
    "- Please see <b> figure (d) single sentence </b> in the section: BERT Structure for various NLP tasks for architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "813957aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06bbb833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1553734464</td>\n",
       "      <td>Sat Apr 18 15:04:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sono23</td>\n",
       "      <td>nice day work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1678151511</td>\n",
       "      <td>Sat May 02 05:42:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>amel_melli</td>\n",
       "      <td>gonna thesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1677758199</td>\n",
       "      <td>Sat May 02 03:49:42 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mel95</td>\n",
       "      <td>really tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>1558763913</td>\n",
       "      <td>Sun Apr 19 09:20:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>geehowquaint</td>\n",
       "      <td>serious vivacious spritely like little blonde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>1555848588</td>\n",
       "      <td>Sat Apr 18 20:52:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bhaddad</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>1551555296</td>\n",
       "      <td>Sat Apr 18 09:21:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>leesteen</td>\n",
       "      <td>grandpa plays guitar hero concentration face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1573417708</td>\n",
       "      <td>Tue Apr 21 01:04:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>littledictator</td>\n",
       "      <td>know u feel vicky nearly get morning sunny stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>1557307389</td>\n",
       "      <td>Sun Apr 19 03:17:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AusRob</td>\n",
       "      <td>1901st update trying decide go potential holid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1556691999</td>\n",
       "      <td>Sat Apr 18 23:54:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>uberlou</td>\n",
       "      <td>uggggh 139 xbox 360 pro woot com wants ts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>1558762876</td>\n",
       "      <td>Sun Apr 19 09:19:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Bikechickie</td>\n",
       "      <td>dude like funniest person ever haha ever singl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "0      NEGATIVE  1553734464  Sat Apr 18 15:04:05 PDT 2009  NO_QUERY   \n",
       "1      NEGATIVE  1678151511  Sat May 02 05:42:21 PDT 2009  NO_QUERY   \n",
       "2      NEGATIVE  1677758199  Sat May 02 03:49:42 PDT 2009  NO_QUERY   \n",
       "3      POSITIVE  1558763913  Sun Apr 19 09:20:06 PDT 2009  NO_QUERY   \n",
       "4      POSITIVE  1555848588  Sat Apr 18 20:52:13 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "99995  POSITIVE  1551555296  Sat Apr 18 09:21:55 PDT 2009  NO_QUERY   \n",
       "99996  NEGATIVE  1573417708  Tue Apr 21 01:04:28 PDT 2009  NO_QUERY   \n",
       "99997  POSITIVE  1557307389  Sun Apr 19 03:17:26 PDT 2009  NO_QUERY   \n",
       "99998  NEGATIVE  1556691999  Sat Apr 18 23:54:14 PDT 2009  NO_QUERY   \n",
       "99999  POSITIVE  1558762876  Sun Apr 19 09:19:56 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \n",
       "0              sono23                                      nice day work  \n",
       "1          amel_melli                                       gonna thesis  \n",
       "2               mel95                                       really tired  \n",
       "3        geehowquaint  serious vivacious spritely like little blonde ...  \n",
       "4             bhaddad                                              sweet  \n",
       "...               ...                                                ...  \n",
       "99995        leesteen       grandpa plays guitar hero concentration face  \n",
       "99996  littledictator  know u feel vicky nearly get morning sunny stu...  \n",
       "99997          AusRob  1901st update trying decide go potential holid...  \n",
       "99998         uberlou          uggggh 139 xbox 360 pro woot com wants ts  \n",
       "99999     Bikechickie  dude like funniest person ever haha ever singl...  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in twitter data on sentiment. (NEGATIVE, POSITIVE for target)\n",
    "# Already cleaned and preprocessed...\n",
    "df = pd.read_csv('twitter_data.csv')\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df = df.drop(['index'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d388bf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE', 'POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267adbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[(label)]\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174eb0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1553734464</td>\n",
       "      <td>Sat Apr 18 15:04:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sono23</td>\n",
       "      <td>nice day work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1678151511</td>\n",
       "      <td>Sat May 02 05:42:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>amel_melli</td>\n",
       "      <td>gonna thesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1677758199</td>\n",
       "      <td>Sat May 02 03:49:42 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mel95</td>\n",
       "      <td>really tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1558763913</td>\n",
       "      <td>Sun Apr 19 09:20:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>geehowquaint</td>\n",
       "      <td>serious vivacious spritely like little blonde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1555848588</td>\n",
       "      <td>Sat Apr 18 20:52:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bhaddad</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1</td>\n",
       "      <td>1551555296</td>\n",
       "      <td>Sat Apr 18 09:21:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>leesteen</td>\n",
       "      <td>grandpa plays guitar hero concentration face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>1573417708</td>\n",
       "      <td>Tue Apr 21 01:04:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>littledictator</td>\n",
       "      <td>know u feel vicky nearly get morning sunny stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>1557307389</td>\n",
       "      <td>Sun Apr 19 03:17:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AusRob</td>\n",
       "      <td>1901st update trying decide go potential holid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>1556691999</td>\n",
       "      <td>Sat Apr 18 23:54:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>uberlou</td>\n",
       "      <td>uggggh 139 xbox 360 pro woot com wants ts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>1558762876</td>\n",
       "      <td>Sun Apr 19 09:19:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Bikechickie</td>\n",
       "      <td>dude like funniest person ever haha ever singl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target         ids                          date      flag  \\\n",
       "0           0  1553734464  Sat Apr 18 15:04:05 PDT 2009  NO_QUERY   \n",
       "1           0  1678151511  Sat May 02 05:42:21 PDT 2009  NO_QUERY   \n",
       "2           0  1677758199  Sat May 02 03:49:42 PDT 2009  NO_QUERY   \n",
       "3           1  1558763913  Sun Apr 19 09:20:06 PDT 2009  NO_QUERY   \n",
       "4           1  1555848588  Sat Apr 18 20:52:13 PDT 2009  NO_QUERY   \n",
       "...       ...         ...                           ...       ...   \n",
       "99995       1  1551555296  Sat Apr 18 09:21:55 PDT 2009  NO_QUERY   \n",
       "99996       0  1573417708  Tue Apr 21 01:04:28 PDT 2009  NO_QUERY   \n",
       "99997       1  1557307389  Sun Apr 19 03:17:26 PDT 2009  NO_QUERY   \n",
       "99998       0  1556691999  Sat Apr 18 23:54:14 PDT 2009  NO_QUERY   \n",
       "99999       1  1558762876  Sun Apr 19 09:19:56 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \n",
       "0              sono23                                      nice day work  \n",
       "1          amel_melli                                       gonna thesis  \n",
       "2               mel95                                       really tired  \n",
       "3        geehowquaint  serious vivacious spritely like little blonde ...  \n",
       "4             bhaddad                                              sweet  \n",
       "...               ...                                                ...  \n",
       "99995        leesteen       grandpa plays guitar hero concentration face  \n",
       "99996  littledictator  know u feel vicky nearly get morning sunny stu...  \n",
       "99997          AusRob  1901st update trying decide go potential holid...  \n",
       "99998         uberlou          uggggh 139 xbox 360 pro woot com wants ts  \n",
       "99999     Bikechickie  dude like funniest person ever haha ever singl...  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f8d0dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice day work\n"
     ]
    }
   ],
   "source": [
    "for txt in df.text:\n",
    "    print(txt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d8ce0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spenc\\AppData\\Roaming\\Python\\Python38\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_lens = []\n",
    "for txt in df.text:\n",
    "    tokens = tokenizer.encode(str(txt), max_length=512)\n",
    "    token_lens.append(len(tokens))\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 256]);\n",
    "plt.xlabel('Token count'); #100 seems to be a solid threshold for the token length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f8a8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50000\n",
       "1    50000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember that I did a lot of precleaning to get the dataframe in this state. If you are curious on how I did that,\n",
    "# the Sentiment Analysis video is here: https://www.youtube.com/watch?v=CzRrD76pnVY&t=785s\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267d449",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "- HuggingFace Documentation for this function we will use: [TFBertForSequenceClassification](https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09d25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load in our models and important packages...'''\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use the base model uncased since Text is lowercased. (uncased just lowercases all incoming raw text)\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2731fb9",
   "metadata": {},
   "source": [
    "### BERT can't just accept raw text. We have to:\n",
    "- Add special tokens to separate sentences for classification\n",
    "- pass sequences of equal length with padding\n",
    "    - padd with zeroes = pad token and ones = real tokens\n",
    "    \n",
    "### Important Tokens and Features for BERT\n",
    "- Special tokens: ([SEP],102) - The marker for the end of a sentence\n",
    "- Classification: ([CLS],101) - Add this token to the beginning of the sentence so BERT knows we are doing classification\n",
    "    - Add a linear layer at the end of the model if you have a regression task\n",
    "- Padding: ([PAD],0)\n",
    "- Unknown tokens: ([UNK],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3abbaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          review,\n",
    "          add_special_tokens=True, # Add [CLS] and [SEP]\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=False,\n",
    "          pad_to_max_length=True, # Adding [PAD] to fit max_len\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt', # returns PyTorch tensors\n",
    "        )\n",
    "\n",
    "        return {\n",
    "          'review_text': review,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07dcce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60%, 20%, 20% split for train, val, test\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fe77cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = SentimentDataset(reviews=df.text.to_numpy(),\n",
    "                         targets=df.target.to_numpy(),\n",
    "                         tokenizer=tokenizer,\n",
    "                         max_len=max_len)\n",
    "\n",
    "    return DataLoader(ds,\n",
    "                      batch_size=batch_size,\n",
    "                      num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81e891aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 100\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Batch\n",
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/sentiment-classification-using-bert/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
